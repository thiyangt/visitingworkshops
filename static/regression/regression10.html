<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>STA 506 2.0 Linear Regression Analysis</title>
    <meta charset="utf-8" />
    <meta name="author" content="Dr Thiyanga S. Talagala" />
    <meta name="date" content="2020-11-20" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/default-fonts.css" rel="stylesheet" />
    <link href="libs/remark-css/duke-blue.css" rel="stylesheet" />
    <link href="libs/remark-css/hygge-duke.css" rel="stylesheet" />
    <link rel="stylesheet" href="libs/cc-fonts.css" type="text/css" />
    <link rel="stylesheet" href="libs/figure-captions.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# STA 506 2.0 Linear Regression Analysis
## Lecture : Identifying Outliers and Influential Cases
### Dr Thiyanga S. Talagala
### 2020-11-20

---



&lt;!--https://tillbe.github.io/outlier-influence-identification.html--&gt;

&lt;!--https://online.stat.psu.edu/stat462/node/170/--&gt;

&lt;!--https://stattrek.com/regression/influential-points.aspx--&gt;

## Introduction

---

## What exactly is an outlier?

- No hard and fast definition.

- An outlier is a data point which is very far, somehow, from the rest of the data.

### Would you consider the red point in either plot as outliers?

.pull-left[

![](regression10_files/figure-html/unnamed-chunk-1-1.png)&lt;!-- --&gt;




]

.pull-right[

![](regression10_files/figure-html/unnamed-chunk-2-1.png)&lt;!-- --&gt;

]

---

## Least-squares regression fit





.pull-left[

![](regression10_files/figure-html/unnamed-chunk-3-1.png)&lt;!-- --&gt;

]

.pull-right[

![](regression10_files/figure-html/unnamed-chunk-4-1.png)&lt;!-- --&gt;

]

Red line: all data including the  red point.

---

## Least-squares regression fit

.pull-left[

![](regression10_files/figure-html/unnamed-chunk-5-1.png)&lt;!-- --&gt;




]

.pull-right[

![](regression10_files/figure-html/unnamed-chunk-6-1.png)&lt;!-- --&gt;

]

Red line: all data including the  red point.

Green line: for all black point (without red point).


---

## 1. A data point can be unusual in its x-value

.pull-left[
![](regression10_files/figure-html/unnamed-chunk-7-1.png)&lt;!-- --&gt;
]

.pull-right[

### Hight leverage point

x-value is either much higher or lower than the mean of the predictor.

]

---

## 2. A data point can be unusual in its y-value

.pull-left[

![](regression10_files/figure-html/unnamed-chunk-8-1.png)&lt;!-- --&gt;

]


.pull-right[

### High discrepancy point


A point has an unusual y-value given its x-value.


]


---
## 3. A data point can be unusual in its x-value and y-value


.pull-left[
![](regression10_files/figure-html/unnamed-chunk-9-1.png)&lt;!-- --&gt;

]


.pull-right[

point that has both high leverage and high discrepancy

]

---


## Assessing leverage

**Hat value:** Helps  to identify extreme `\(X\)` values.

**In simple linear regression**

`$$h_{ii} = \frac{1}{n} + \frac{(x_i-\bar{x})^2}{\sum_{j=1}^n(x_j - \bar{x})^2},$$`

where `\(i = 1, 2, ... n\)`

Hat value is bound between `\(1/n\)` and 1, with 1 denoting highest leverage.

n - total number of points

---


## Assessing leverage (cont.)

**In multiple linear regression**


`\(Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + ...+\beta_pX_p + \epsilon\)`

.pull-left[

`$$Y = \begin{bmatrix}
Y_{1}\\
Y_{2}\\
.\\
.\\
.\\
Y_{n}
\end{bmatrix}$$`

]

.pull-right[

`$$X = \begin{bmatrix}
1 \text{ } x_{11} \text{ } x_{12} \text{ } ... \text{ } x_{1p}\\
1 \text{ } x_{21} \text{ } x_{22} \text{ } ... \text{ }x_{2p}\\
.\\
.\\
.\\
1 \text{ } x_{n1} \text{ } x_{n2} \text{ }...\text{ } x_{np}
\end{bmatrix}$$`

]

`$$H = X(X'X)^{-1}X'$$`


Hat matrix diagonal is a standardized measure of the distance of the `\(i\)`th observation from the center (or centroid) of the `\(x-\)`space.

The leverage value `\(h_{ii}\)` does not depend on the response `\(Y_i\)`.
---

## Assessing leverage: Example

.pull-left[
![](regression10_files/figure-html/unnamed-chunk-10-1.png)&lt;!-- --&gt;
]

.pull-right[


```
           y    x
1   15.37697  1.0
2   15.30155  1.0
3   23.90198  2.0
4   33.86959  3.0
5   37.20347  3.5
6   45.72057  4.0
7   65.93912  6.0
8   69.77062  6.5
9   71.75913  6.5
10  75.11737  7.0
11  76.14688  7.2
12  87.90926  8.2
13  91.19637  8.5
14  94.62842  9.0
15 104.87674 10.0
16 500.00000 20.0
```


]

---

## Assessing leverage: Example (cont)


```r
library(broom)
data.fit &lt;- lm(y ~x, data=example.data)
augment(data.fit)
```

```
# A tibble: 16 x 8
       y     x .fitted .resid .std.resid   .hat .sigma  .cooksd
   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;
 1  15.4   1    -35.7    51.0      1.18  0.157   46.3   0.130  
 2  15.3   1    -35.7    51.0      1.18  0.157   46.3   0.129  
 3  23.9   2    -13.0    36.9      0.840 0.125   47.5   0.0505 
 4  33.9   3      9.63   24.2      0.543 0.100   48.3   0.0165 
 5  37.2   3.5   21.0    16.2      0.362 0.0902  48.6   0.00651
 6  45.7   4     32.3    13.4      0.298 0.0816  48.6   0.00396
 7  65.9   6     77.6   -11.6     -0.256 0.0632  48.7   0.00220
 8  69.8   6.5   88.9   -19.1     -0.420 0.0625  48.5   0.00588
 9  71.8   6.5   88.9   -17.1     -0.376 0.0625  48.5   0.00472
10  75.1   7    100.    -25.1     -0.552 0.0634  48.3   0.0103 
11  76.1   7.2  105.    -28.6     -0.629 0.0642  48.1   0.0136 
12  87.9   8.2  127.    -39.5     -0.872 0.0720  47.4   0.0295 
13  91.2   8.5  134.    -43.0     -0.951 0.0756  47.2   0.0370 
14  94.6   9    146.    -50.9     -1.13  0.0828  46.5   0.0577 
15 105.   10    168.    -63.3     -1.42  0.102   45.1   0.115  
16 500    20    395.    105.       3.74  0.641    1.14 12.5    
```

---

## Assessing leverage: Example (cont)


`$$\text{cut off} = \frac{2p}{n},$$`

`\(p\)` - number of predictors/ x- variables.

`\(n\)` - number of observations.

In this case `$$\text{cut off} = \frac{2p}{n} = \frac{2 \times 1}{16} = 0.125$$`

We say a point is a high leverage point if

`$$h_{ii} &gt; \frac{2p}{n}$$`

This cut off does not apply `\(\frac{2p}{n} &gt; 1\)`.

---

## What to do when you find outliers?

- Explore! (data entry errors, recording errors, etc.)

---

## Influence

- a point with high leverage can dramatically impact the regreassion model.

.pull-left[

**All points**

![](regression10_files/figure-html/unnamed-chunk-13-1.png)&lt;!-- --&gt;

]

.pull-right[

**Only black points**

![](regression10_files/figure-html/unnamed-chunk-14-1.png)&lt;!-- --&gt;


]

- Influence - measures how much impact a point has on the regression mode

---

## Measure of Influence (cont.)

Cook's distance, `\(D_i\)`, is a measure of influence.



```r
augment(data.fit)
```

```
# A tibble: 16 x 8
       y     x .fitted .resid .std.resid   .hat .sigma  .cooksd
   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;
 1  15.4   1    -35.7    51.0      1.18  0.157   46.3   0.130  
 2  15.3   1    -35.7    51.0      1.18  0.157   46.3   0.129  
 3  23.9   2    -13.0    36.9      0.840 0.125   47.5   0.0505 
 4  33.9   3      9.63   24.2      0.543 0.100   48.3   0.0165 
 5  37.2   3.5   21.0    16.2      0.362 0.0902  48.6   0.00651
 6  45.7   4     32.3    13.4      0.298 0.0816  48.6   0.00396
 7  65.9   6     77.6   -11.6     -0.256 0.0632  48.7   0.00220
 8  69.8   6.5   88.9   -19.1     -0.420 0.0625  48.5   0.00588
 9  71.8   6.5   88.9   -17.1     -0.376 0.0625  48.5   0.00472
10  75.1   7    100.    -25.1     -0.552 0.0634  48.3   0.0103 
11  76.1   7.2  105.    -28.6     -0.629 0.0642  48.1   0.0136 
12  87.9   8.2  127.    -39.5     -0.872 0.0720  47.4   0.0295 
13  91.2   8.5  134.    -43.0     -0.951 0.0756  47.2   0.0370 
14  94.6   9    146.    -50.9     -1.13  0.0828  46.5   0.0577 
15 105.   10    168.    -63.3     -1.42  0.102   45.1   0.115  
16 500    20    395.    105.       3.74  0.641    1.14 12.5    
```



---

## Measure of Influence (cont.)

 - We usually consider points for which  `\(D_i &gt; 1\)` to be influencital (Montgomery, et al.).
 

```
# A tibble: 16 x 8
       y     x .fitted .resid .std.resid   .hat .sigma  .cooksd
   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;
 1  15.4   1    -35.7    51.0      1.18  0.157   46.3   0.130  
 2  15.3   1    -35.7    51.0      1.18  0.157   46.3   0.129  
 3  23.9   2    -13.0    36.9      0.840 0.125   47.5   0.0505 
 4  33.9   3      9.63   24.2      0.543 0.100   48.3   0.0165 
 5  37.2   3.5   21.0    16.2      0.362 0.0902  48.6   0.00651
 6  45.7   4     32.3    13.4      0.298 0.0816  48.6   0.00396
 7  65.9   6     77.6   -11.6     -0.256 0.0632  48.7   0.00220
 8  69.8   6.5   88.9   -19.1     -0.420 0.0625  48.5   0.00588
 9  71.8   6.5   88.9   -17.1     -0.376 0.0625  48.5   0.00472
10  75.1   7    100.    -25.1     -0.552 0.0634  48.3   0.0103 
11  76.1   7.2  105.    -28.6     -0.629 0.0642  48.1   0.0136 
12  87.9   8.2  127.    -39.5     -0.872 0.0720  47.4   0.0295 
13  91.2   8.5  134.    -43.0     -0.951 0.0756  47.2   0.0370 
14  94.6   9    146.    -50.9     -1.13  0.0828  46.5   0.0577 
15 105.   10    168.    -63.3     -1.42  0.102   45.1   0.115  
16 500    20    395.    105.       3.74  0.641    1.14 12.5    
```

&lt;!--Interpretations: page 213--&gt;

---
## Measure of Influence (cont.)

Remember that leverage alone does not mean a point exerts high influence, but it certainly means it's worth investigating. 
---
-

- The field of **robust statistics** is concerned with more advanced methods of dealing with outliers

&lt;!--The field of robust statistics is concerned with more sophisticated ways of dealing with outliers--&gt;

---
## Influential


```r
library(ggfortify)
autoplot(data.fit)
```

![](regression10_files/figure-html/unnamed-chunk-17-1.png)&lt;!-- --&gt;


---

## Assessing discrepancy

---

## Assessing influence

---
## Test Your Understanding
In the context of regression analysis, which of the following statements are true?

I. When the data set includes an influential point, the data set is nonlinear.
II. Influential points always reduce the coefficient of determination.
III. All outliers are influential data points.

&lt;!--https://stattrek.com/regression/influential-points.aspx--&gt;


&lt;!--The correct answer is (E). Data sets with influential points can be linear or nonlinear. In this lesson, we went over an example in which an influential point increased the coefficient of determination. With respect to regression, outliers are influential only if they have a big effect on the regression equation. Sometimes, outliers do not have big effects. For example, when the data set is very large, a single outlier may not have a big effect on the regression equation.--&gt;

---

class: center, middle



Acknowledgement

Introduction to Linear Regression Analysis, Douglas C. Montgomery, Elizabeth A. Peck, G. Geoffrey Vining


All rights reserved by 

[Dr. Thiyanga S. Talagala](https://thiyanga.netlify.app/)
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
